# Fake News Classifier

This project demonstrates the classification of fake and real news using **NLP techniques** and **Word2Vec embeddings**. The focus is on leveraging pre-trained embeddings from Gensim's Google News Word2Vec model and building a robust classification pipeline using machine learning models.

## Overview
Fake news refers to misinformation or disinformation spread through various channels like social media or instant messaging platforms. This classifier aims to identify whether a given news statement is real or fake, addressing the societal problems caused by fake news.

## Features
- Utilizes **Word2Vec embeddings** for text representation.
- Implements a pipeline for **text preprocessing** and vectorization.
- Trains a machine learning model (**Gradient Boosting Classifier**) for binary classification.
- Achieves a high classification accuracy of **98%**.

## Dataset
The dataset used is the **Fake and Real News Dataset** from [Kaggle](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset). 

### Columns:
- `Text`: The news statements/messages.
- `Label`: Indicates whether the news is `Fake` or `Real`.

### Dataset Statistics:
- 9,900 total rows
  - `Fake`: 5,000
  - `Real`: 4,900

## Pipeline
1. **Text Preprocessing:**
   - Stopword removal
   - Lemmatization
   - Vectorization using Gensim's Word2Vec embeddings

2. **Model Training:**
   - Splits data into train (80%) and test (20%) sets using stratified sampling.
   - Trains a **Gradient Boosting Classifier**, which outperformed other algorithms like Random Forest and Naive Bayes.

3. **Evaluation:**
   - Uses metrics such as **precision**, **recall**, **f1-score**, and **accuracy**.
   - Displays a **confusion matrix** for better insights.

## Implementation
### Key Libraries:
- **Pandas**: For data manipulation.
- **Numpy**: For numerical operations.
- **Gensim**: For Word2Vec embeddings.
- **SpaCy**: For text preprocessing.
- **Scikit-learn**: For train-test splitting, machine learning, and evaluation.
- **Matplotlib/Seaborn**: For visualizations.

### Preprocessing and Vectorization:
The text is preprocessed using SpaCy's language model (`en_core_web_lg`). Word embeddings are generated by:
- Removing stopwords and punctuation.
- Lemmatizing the text.
- Aggregating word embeddings using their mean to create a numeric representation of the entire news statement.

### Training and Evaluation:
- Model: **Gradient Boosting Classifier**
- Metrics:
  - **Precision**: 98%
  - **Recall**: 98%
  - **F1-Score**: 98%

### Example Predictions:
Given test news, the classifier can identify their nature (`Real` or `Fake`). For example:
```python
test_news = [
    "Michigan governor denies misleading U.S. House on Flint water...",
    "WATCH: Fox News Host Loses Her Sh*t, Says Investigating Russia...",
    "Sarah Palin Celebrates After White Man Who Pulled Gun On Black..."
]

predictions = clf.predict(test_news_vectors)
print(predictions)  # Output: [1, 0, 0]
